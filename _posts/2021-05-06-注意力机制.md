---
layout: post
title:  注意力机制
description: "在传统神经网络模型中，从输入层到隐藏层再到输出层，层与层之间是全连接的，每层之间的点是无连接的。"
modified: 2021-03-06T16:00:15-04:00
tags: [Attention, 注意力机制, RNN, 循环神经网络, Self-Attention]
---

在传统神经网络模型中，从输入层到隐藏层再到输出层，层与层之间是全连接的，每层之间的点是无连接的。

<!-- more -->

**序列模型RNN**



在传统神经网络模型中，从输入层到隐藏层再到输出层，层与层之间是全连接的，每层之间的点是无连接的。在RNN模型中，神经元的输出可以在下一时刻直接作用到自身，即第i层神经元在t时刻的输入，除了(i-1)层神经元在该时刻的输出外，还包括其自身在(t-1)时刻的输出。另外，理论上RNN能够对任何长度的序列数据进行处理。但在实践当中，为了降低模型复杂性往往假设当前的状态只与前面的几个状态相关。这也在一定程度上造成了RNN记忆力越往前越弱，越往后越强的情况。



**注意力机制原理**



Attention机制直接跳出了上述RNA循环序列前后依赖的问题，这样的结构解放了模型并行计算受限的困扰。从字面意思上就可以看出，注意力机制模拟人类接触信号的方式。人只关注重点部分而不是全量信息，对重点部分的信息给予更多的注意力，在数学模型中即给予更高的权重值。比方出看图说话时，我们要求模型用一句话描述一副图片的内容，模型所生成的词语应该对应图中的不同部分。当解码器进行解码时，应该给图中“合适”的部分分配更多的注意力和权重。在Encoder-Decoder范式中，编码器把所有的输入序列都编码成一个统一的语义编码层c再解码。c中必须包含原始序列中的所有信息。它的长度就成了限制模型性能的瓶颈。如机器翻译问题。当要翻译的句子较长，是一个c可能存不下那么多的信息就会造成翻译精度下降。



Attention机制通过在每一个时间输入不同的语义编码c~i~来解决这个问题。如图a表示带有Attention机制的Decoder。每一个c~i~会自动选取与当前所要输出y~i~最合适的上下位信息。具体来讲，上下文信息c~i~就来自所有h~j~对a~ij~的加权和，这些权重a~ij~同样是从模型中学习出来的。如图b。



以中英文翻译为例，输入的序列是“我爱吃苹果”。Encoder中的h~i~={h~1~, h~2~, h~3~, h~4~, h~5~,}就可以看成是“我”“爱”“吃”“苹”“果”所代表的信息，第一个上下文c~i~的值是h~i~与a~1~={a~11~,a~12~,a~13~,a~14~,a~15~}元素的加权求和的结果。在翻译成英文时，c~1~和“我”这个字最相关的a~11~值就比较大，而相应的a~12~、a~13~、a~14~、a~15~值就比较小。一直类推，上下文c~i~关注了所有可能的因素，只是Attention权重不一样。这样就能让模型学出不同语境中“苹果”的含义了。翻译的计算过程如下，*表示点乘。


$$
h_1 * a_{11} + h_2 * a_{12} + h_3 * a_{13} + h_4 * a_{14} + h_5 * a_{15} = c_1 \to		 I
$$

$$
h_1 * a_{21} + h_2 * a_{22} + h_3 * a_{23} + h_4 * a_{24} + h_5 * a_{25} = c_1 \to		 Love
$$

$$
h_1 * a_{31} + h_2 * a_{32} + h_3 * a_{33} + h_4 * a_{34} + h_5 * a_{35} = c_1 \to		 Apples
$$



