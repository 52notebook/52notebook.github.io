---
layout: post
title:  语音合成技术总结
description: "语音合成技术主要包含***\*文本前端\****（Text Frontend）、***\*声学模型\****（Acoustic Model） 和***\*声码器\****（Vocoder）三个主要模块。"
modified: 2021-06-29T16:00:15-06:00
tags: [解码算法, NLP算法, 维特比, 束搜索, Beam Search,贪心算法] 

---

语音合成技术主要包含***\*文本前端\****（Text Frontend）、***\*声学模型\****（Acoustic Model） 和***\*声码器\****（Vocoder）三个主要模块。

<!-- more -->



语音合成技术主要包含***\*文本前端\****（Text Frontend）、***\*声学模型\****（Acoustic Model） 和***\*声码器\****（Vocoder）三个主要模块。

 

- 文本前端模块将原始文本转换为字符/音素

- 声学模型将字符/音素转换为声学特征，如线性频谱图、mel 频谱图、LPC 特征等

- 声码器将声学特征转换为波形

 

 ![语音合成基本流程图](/images/00/tts_0108.png)

语音合成基本流程图



 

## **文本前端**

文本前端模块主要包含： 分段（Text Segmentation）、文本正则化（Text Normalization, TN）、分词（Word Segmentation, 主要是在中文中）、词性标注（Part-of-Speech, PoS）、韵律预测（Prosody）和字音转换（Grapheme-to-Phoneme，G2P）等。

 

其中最重要的模块是 文本正则化 模块和字音转换（TTS中更常用G2P代指）模块。

 

各模块输出示例:

 

•Text:全国一共有112所211高校

•Text Normalization: 全国一共有一百一十二所二一一高校

•Word Segmentation: 全国/一共/有/一百一十二/所/二一一/高校/

•G2P（注意此句中“一”的读音）:

  quan2 guo2 yi2 gong4 you3 yi4 bai3 yi1 shi2 er4 suo3 er4 yao1 yao1 gao1 xiao4

  （可以进一步把声母和韵母分开）

  q uan2 g uo2 y i2 g ong4 y ou3 y i4 b ai3 y i1 sh i2 er4 s uo3 er4 y ao1 y ao1 g ao1 x iao4

  （把音调和声韵母分开）

  q uan g uo y i g ong y ou y i b ai y i sh i er s uo er y ao y ao g ao x iao

  0 2 0 2 0 2 0 4 0 3 ...

• Prosody (prosodic words #1, prosodic phrases #2, intonation phrases #3, sentence #4):

  全国#2一共有#2一百#1一十二所#2二一一#1高校#4

  （分词的结果一般是固定的，但是不同人习惯不同，可能有不同的韵律）

## **声学模型**

声学模型将字符/音素转换为声学特征，如线性频谱图、mel频谱图、LPC特征等。声学特征以“帧”为单位，一般一帧是10ms左右，一个音素一般对应5~20帧左右。声学模型需要解决的是“不等长序列间的映射问题”，“不等长”是指，同一个人发不同音素的持续时间不同，同一个人在不同时刻说同一句话的语速可能不同，对应各个音素的持续时间不同，不同人说话的特色不同，对应各个音素的持续时间不同。这是一个困难的“一对多”问题。

 

\#卡尔普陪外孙玩滑梯

000001|baker_corpus|sil 20 k 12 a2 4 er2 10 p 12 u3 12 p 9 ei2 9 uai4 15 s 11 uen1 12 uan2 14 h 10 ua2 11 t 15 i1 16 sil 20

声学模型主要分为自回归模型和非自回归模型。自回归模型在t时刻的预测需要依赖t-1时刻的输出作为输入，预测时间长，但是音质相对较好；非自回归模型不存在预测上的依赖关系，预测时间快，音质相对较差。

 

主流声学模型：

自回归模型： Tacotron、Tacotron2 和 Transformer TTS 等

非自回归模型： FastSpeech、SpeedySpeech、FastPitch 和 FastSpeech2 等

## **声码器**

声码器将声学特征转换为波形，它需要解决的是“信息缺失的补全问题”。信息缺失是指，在音频波形转换为频谱图时，存在相位信息的缺失；在频谱图转换为mel频谱图时，存在频域压缩导致的信息缺失。假设音频的采样率是16kHz，即1s的音频有16000个采样点，一帧的音频有10ms，则1s中包含100帧，每一帧有160个采样点。声码器的作用就是将一个频谱帧变成音频波形的160个采样点，所以声码器中一般会包含上采样模块。

 

与声学模型类似，声码器也分为自回归模型和非自回归模型：

 

自回归模型：WaveNet、WaveRNN和LPCNet等

非自回归模型：Parallel WaveGAN、Multi Band MelGAN、Style MelGAN 和 HiFiGAN 等
