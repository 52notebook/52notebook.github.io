---
layout: post
title:  衡量信息检索系统的关键指标
description: "信息检索系统是指在一个非结构化数据库中寻找满足需求的信息。"
modified: 2021-06-12T22:00:15-06:00
tags: [评价指标, 检索系统] 

---

信息检索系统是指在一个非结构化数据库中寻找满足需求的信息。

<!-- more -->

   * [信息检索系统](#信息检索系统)
   * [混淆矩阵](#混淆矩阵)
   * [评价指标](#评价指标)
      * [准确率](#准确率)
      * [精确率](#精确率)
      * [召回率](#召回率)
      * [MRR](#mrr)
      * [MAP](#map)
      * [NDCG](#ndcg)

## 信息检索系统



信息检索系统是指在一个非结构化数据库中寻找满足需求的信息。在普遍情况下，数据主要是文本集，数据库储存在计算机上，信息主要是文档。常用的搜索引擎外，在电子邮箱、计算机文件系统等查询是信息检索系统的典型应用场景。

信息检索系统被广泛使用，它帮助人们快速简单地获取相关信息，其准确性和相关反应速度是衡量用户体验的两个关键指标。准确性取决于算法，包括文档的预处理、索引和排序等。



## 混淆矩阵



在机器学习领域，混淆矩阵是以一种特定的矩阵，它可以非常容易而清晰地表明多个类别间是否有混淆。

TP:真阳性

TN:真阴性

FP:假阳性

FN:假阴性

信息检索系统

|                           |     相关(Relevant)，正例     |          不相关，负例          |
| :-----------------------: | :--------------------------: | :----------------------------: |
|    被检索到(Retrieved)    |    TP，系统检索到相关文档    |    FP，系统检索到不相关文档    |
| 未被检索到(Not Retrieved) | FN，相关但系统未检索到的文档 | TN，不相关且系统未检索到的文档 |



## 评价指标



### 准确率

**准确率**(Accuracy)代表在给定的测试数据集当中，分类器正确分类的样本数与总样本数之比。

$$ Accuracy = \frac{TP+TN}{P+N}$$

P+N表示全部样本数



### 精确率

**精确率**(Precision)表示在实际为正例且被预测为正例的样本占所有被预测为正例的样本比例。

$$Precision = \frac{TP}{TP+FP}$$



### 召回率

**召回率**(Recall)是指实际为正例且被预测为正例的样本占实际为正例的比例。

$$Recall = \frac{TP}{TP+FN}$$

精确率与召回率是负相关的，模型的表现需要综合考虑精确率与召回率权衡。F1值是精确率与召回率的加权调和平均。

$$F1 = \frac{2*Precision * Recall}{Precision + Recall}$$



### MRR

**MRR**(Mean Reciprocal Rank)是指只考虑在于当前问题相关的所有的答案中，rank最靠前的那个答案。MRR值等于每个样本的该答案排序的倒数和的均值。一般用于问题与答案是否匹配的二状态问题中。假设对于问题q1答案排序为$$a1、a2、a3$$，与问题q1相关的答案为a3；对于问题q2答案排序为$$a4、a5、a6、a7$$，与问题q2相关的答案是a5和a6，那么：

$$MRR = \frac{1/3 + 1/2}{2} = 5/12$$

MRR 计算公式:

$$MRR = \frac{\sum{}1/(fisrt \space match  \space answer  \space rank)}{n}$$

比如，有一个检索《三国演义》人物关系的系统，每个查询给出三个结果，并且按照相关度递减排序。以下表为例，计算

$$MRR = \frac{1+1/3+0}{3} = 4/9$$

**需要特别注意的是，相对值只考虑第一个相关文档的排名，如果没有命中，那么相对值为0**



| 查询   | 候选结果               | 答案   | 排名 | 相对值 |
| ------ | ---------------------- | ------ | ---- | ------ |
| 诸葛亮 | 诸葛亮，诸葛瑾，诸葛诞 | 诸葛亮 | 1    | 1      |
| 奉孝   | 苟攸，贾诩，郭嘉       | 郭嘉   | 3    | 1/3    |
| 公瑾   | 陆逊，张昭，吕蒙       | 未命中 | 0    | 0      |



### MAP

**MAP**(Mean Average Precision)也是衡量问题与答案是否匹配的一个指标。与MRR不同的是，MAP考虑所有与问题相关的答案排序。假设对于q1，与之相关的答案排序是1，3，6(共有三个答案与问题q1相关，其余答案不相关)，那么可以计算它的AP值：

$$AP_1 = (1+2/3+3/6) / 3$$

对于q2，与之相关的答案排序是2,5,7,8(共有5个答案与q2相关，有一个没有被召回)，那么它的AP：

$$AP_2 = (1/2+2/5+3/7+4/8+0)/5$$

因此该排序算法的$$MAP = (AP_1 + AP_2) / 2$$

MAP计算公式：

$$MAP = average\sum()AP_j$$

$$AP_j = average\sum(\frac{order}{rank})$$



### NDCG

**NDCG**(Normalized Discounted Cumulative Gain)，该指标可以用于不同打分的答案，也就是不局限于二状态的情况。一个问题和不同的答案的相关度可以用不同分数表示。NDCG由DCG和iDCG得到。iDCG是表示最理想排序情况下的DCG分数。假设我们只考虑n个文档排序中的前K个文档，那么：



$$DCG@K = \sum_{i=1}^p(\frac{2^{rel_i}-1}{log_2^{(i+1)}})$$



$$iDCG@K = \sum_{i=1}^{REL}(\frac{2^{rel_i}-1}{log_2^{(i+1)}})$$

$$NDCG@K = \frac{DCG_{K}}{iDCG_{k}}$$

其中，$$rel_i$$表示当前排序$$i$$的文档与问题的相关度，REL表示按照相关度排序的列表。假设对于一个问题Q，得到排序文档D1,D2,D3,而每个文档与Q的相关度分别是3，4，2，那么可以计算出：



$$DCG = \frac{2^3-1}{log_2(2)} +  \frac{2^4-1}{log_2(3)} +  \frac{2^2-1}{log_2(4)}$$

$$iDCG = \frac{2^4-1}{log_2(2)} +  \frac{2^3-1}{log_2(3)} +  \frac{2^2-1}{log_2(4)}$$

$$NDCG = \frac{DCG}{iDCG}$$

