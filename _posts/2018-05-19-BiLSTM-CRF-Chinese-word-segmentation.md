---
layout: post
title: 基于BiLSTM-CRF中文分词
description: "中文分词是中文自然语言处理中关键基础技术之一。目前，传统机器学习分词算法依赖人工特征工程，该方法需要大量人工验证特征的有效性；而基于神经网络的深度学习能使模型自动学习特征成为可能，并能有效建模长距离信息依赖。"
modified: 2018-05-18T09:00:45-06:00
tags: [LSTM, RNN, BiLSTM, CRF, 中文分词]
---

#### 一、介绍

中文分词是中文自然语言处理中关键基础技术之一。目前，传统机器学习分词算法依赖人工特征工程，该方法需要大量人工验证特征的有效性；基于神经网络的深度学习能使模型自动学习特征成为可能，并能有效建模长距离信息依赖。

中文分词是其他中文文本任务( 如命名实体识别、句法分析、语义分析等)的前期关键处理环节，其分词 的准确性对中文自然语言处理尤为重要。但是由于中文句子是连续的文 字，标点符号只是对句和段进行划分，与英文单词以空格划分存在显著差异；同时中文存在大量的歧义和未登录词问题等等严重影响最终的切分效果，本文将探索基于深度学习技术在中文分词上实践应用。


中文歧义识别：歧义是指同样一个句子，有多种切分方法。

未登录词识别问题：由于中文本身的复杂性，不存在包含所有中文词语的词典，待切分语句中很有可能存在词典中没有收录的词，即未登录词。

#### 二、基于神经网络的中文分词

在中文分词研究中，中文分词任务通常被看作一个字符序列标注任务，即给字符序列中的每个字符标注一个词位标签。其中，使用最为广泛的是四词位标签集(B ，M ，E ，S )。对于多字词，词语中的第一个汉字标签为B，中间字的标签为M，最 后一个汉字标签为E;对于单字词，其标签为S。

#### 三、LSTM模型
由于RNN模型维护着历史状态信息，它使得RNN能利用长距离依赖预测当前输出。但RNN随着不断递归，面临梯度呈指数级爆炸或消失问题模型难以训练问题。


**RNN图解**
![RNN模型](http://p71cwk72x.bkt.clouddn.com/18-5-19/65738414.jpg)

LSTM模型是RNN的一种变种，它是把RNN模型隐藏层状态的更新替换成使用特定结构的记忆单元的处理。结果，LSTM模型能更好地处理长时依赖问题。



$$input \space gate: \space \space  i_t = \sigma(W^{(i)}xt +\space U^{i}h_{t-1})$$

$$forget \space gate: \space \space f_t= \sigma(W^{f}x_t \space + U^{f}h_{t-1})$$


$$output \space gate: \space \space o_t = \sigma(W^{o}x_t \space + U^{o}h_{t-1})$$


$$new \space memry  \space cell: \space \space \tilde{c_{t}} = tanh(W^{c}x_t \space + U^{c}h_{t-1})$$


$$final \space memry \space cell: \space \space c_t = f_t c_{t-1} + i_t \tilde{c_{t}}$$


$$h_t = o_t \cdot tanh(c_t)$$


$$y_t = o_t \cdot tanh(c_t)$$


**LSTM图详解1**
![LSTM图详解](http://p71cwk72x.bkt.clouddn.com/18-5-19/72824696.jpg)




$$\sigma$$ 表示sigmoid函数，$$i$$、$$f$$、$$o$$、$$c$$分别表示输入门、忘记门、输出门、记忆单元。可以看出，当忘记门$$f_t$$接近0时，表示忽略之前的记忆单元信息，只会把当前时刻候补记忆单元作为输入。

##### 1、 BiLSTM模型

在序列标注任务中，为了能够挖掘有效历史信息和将来的信息，模型使用双向LSTM网络结构。BiLSTM模型能够在任意时刻通过**forward state**充分利用历史信息，同时通过**backard state**利用将来的信息。BiLSTM模型学习参数的更新使用**back-propagation through time (BPTT)算法**，该模型在forward和backard阶段与一般模型不同之处在于隐藏层对于所有的time step都要展开计算。


##### 2、CRF Network

在标签推理时有两种利用相邻标签信息的方式，一种是在每一时刻预测标签的分布并解码最优标签序列；另一种是替代单一标签使用句子级全局信息的预测标签，也就是CRF网络。


CRF在训练时，利用训练数据集通过极大似然估计或者正则化的极大似然估计得到条件概率模型$$\hat{P}(Y|X)$$；在预测时，给定输入序列x,求出条件概率
$$\hat{P}(y|x)$$最大输出序列$$\hat{y}$$。


**CRF结构图2**


![CRF结构](http://p71cwk72x.bkt.clouddn.com/18-5-19/69266087.jpg)

##### 3、BiLSTM-CRF
BiLSTM模型既能够能够利用past input feature 和future input feature，又可以充分利用句子层级的标签信息。CRF网络结构使用连接神经网络输出的连接线表示。

**BiLSTM-CRF模型3**
![BiLSTM-CRF模型](http://p71cwk72x.bkt.clouddn.com/18-5-19/85677857.jpg)

###### 3.1、BiLSTM-CRF 框架流程
该神经网络模型框架主要由三部分构成，字向量(Word Embedding)技术将输入的中文字符转成一个特征向量，中间部分是BiLSTM神经网络结构，最后一层是标签判别层，计算各标签路径下句子评分值。

对于一个长度为n的句子$$c^{1:n}$$ ，取一个包括上下文和当前字、长度为 $$\omega$$的词窗(**笔者做实验context feature选用的是unigram feature**)。词窗口上下文经过第1层处理将每个字转换成其相对应的长度为d 的向量$$v_i$$，将ω个向量组成$$\omega \cdot d$$ 的输入矩阵 x(t) 作为神经网络的输入层。具体模型详见图。

###### 3.2、各标签路径下句子评分计算

使用$$[f_\theta ]_{i,t}$$表示神经网络输出，也就是对句子$$[x]^T_1$$在$$t$$处字是标签$$i$$的评分；然后由于句子标签前后具有很强的依赖关系，引入转移矩阵$$A$$。$$A_{ij}$$表示从标签$$i$$转移到$$j$$的权重值，
$$A_{ij}$$值越大，表明由$$i$$标签转移到$$j$$标签可能性越大。那么沿$$[i]^T_1$$标签路径句子$$[x]^T_1$$评分是等于转移矩阵和神经网络输出之和。

$$s([x]_1^T + [i]^T_1 + \tilde \theta) = \sum^T_{t1}([A]_{[i]_{t-1} \space + [f_\theta ]_{[i]_t}, t)$$



**BiLSTM-CRF模型架构4**
![BiLSTM-CRF模型架构](http://p71cwk72x.bkt.clouddn.com/18-5-19/22249423.jpg)

#### 四、总结

笔者使用BiLSTM-CRF模型做中文分词试验准确率达到96.1%，badcase中由很多歧义性词语，比如海运业等词，这类词笔者任务还是仁者见仁了，分词不存在完美标准。
$$
海运业分成:  海运   业
造船业分成:  造船  业
感动了四乡八镇分成:  感动  了  四  乡  八   镇
$$
接下来尝试的改进方向:1、模型引入自定义词表功能，凭借该词词频大小控制其是否分割；2、使用预训练的词向量；3、与GRU模型做对比两模型训练速度和分割性能。
